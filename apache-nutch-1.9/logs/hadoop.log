2014-10-01 17:52:03,343 INFO  crawl.Injector - Injector: starting at 2014-10-01 17:52:03
2014-10-01 17:52:03,344 INFO  crawl.Injector - Injector: crawlDb: -solr/crawldb
2014-10-01 17:52:03,345 INFO  crawl.Injector - Injector: urlDir: urls
2014-10-01 17:52:03,346 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2014-10-01 17:52:03,656 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-10-01 17:52:03,701 WARN  snappy.LoadSnappy - Snappy native library not loaded
2014-10-01 17:52:04,209 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2014-10-01 17:52:04,935 INFO  crawl.Injector - Injector: Total number of urls rejected by filters: 1
2014-10-01 17:52:04,935 INFO  crawl.Injector - Injector: Total number of urls after normalization: 0
2014-10-01 17:52:04,935 INFO  crawl.Injector - Injector: Merging injected urls into crawl db.
2014-10-01 17:52:05,159 INFO  crawl.Injector - Injector: overwrite: false
2014-10-01 17:52:05,159 INFO  crawl.Injector - Injector: update: false
2014-10-01 17:52:06,032 INFO  crawl.Injector - Injector: URLs merged: 0
2014-10-01 17:52:06,036 INFO  crawl.Injector - Injector: Total new urls injected: 0
2014-10-01 17:52:06,037 INFO  crawl.Injector - Injector: finished at 2014-10-01 17:52:06, elapsed: 00:00:02
2014-10-01 17:53:49,206 INFO  crawl.Injector - Injector: starting at 2014-10-01 17:53:49
2014-10-01 17:53:49,207 INFO  crawl.Injector - Injector: crawlDb: -solr/crawldb
2014-10-01 17:53:49,207 INFO  crawl.Injector - Injector: urlDir: urls
2014-10-01 17:53:49,208 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2014-10-01 17:53:49,506 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-10-01 17:53:49,561 WARN  snappy.LoadSnappy - Snappy native library not loaded
2014-10-01 17:53:50,147 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2014-10-01 17:53:50,834 INFO  crawl.Injector - Injector: Total number of urls rejected by filters: 1
2014-10-01 17:53:50,834 INFO  crawl.Injector - Injector: Total number of urls after normalization: 0
2014-10-01 17:53:50,834 INFO  crawl.Injector - Injector: Merging injected urls into crawl db.
2014-10-01 17:53:51,056 INFO  crawl.Injector - Injector: overwrite: false
2014-10-01 17:53:51,056 INFO  crawl.Injector - Injector: update: false
2014-10-01 17:53:51,923 INFO  crawl.Injector - Injector: URLs merged: 0
2014-10-01 17:53:51,927 INFO  crawl.Injector - Injector: Total new urls injected: 0
2014-10-01 17:53:51,928 INFO  crawl.Injector - Injector: finished at 2014-10-01 17:53:51, elapsed: 00:00:02
2014-10-01 17:54:25,063 INFO  crawl.Injector - Injector: starting at 2014-10-01 17:54:25
2014-10-01 17:54:25,064 INFO  crawl.Injector - Injector: crawlDb: -solr/crawldb
2014-10-01 17:54:25,064 INFO  crawl.Injector - Injector: urlDir: urls
2014-10-01 17:54:25,064 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2014-10-01 17:54:25,369 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-10-01 17:54:25,429 WARN  snappy.LoadSnappy - Snappy native library not loaded
2014-10-01 17:54:25,984 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2014-10-01 17:54:26,684 INFO  crawl.Injector - Injector: Total number of urls rejected by filters: 1
2014-10-01 17:54:26,684 INFO  crawl.Injector - Injector: Total number of urls after normalization: 0
2014-10-01 17:54:26,684 INFO  crawl.Injector - Injector: Merging injected urls into crawl db.
2014-10-01 17:54:26,905 INFO  crawl.Injector - Injector: overwrite: false
2014-10-01 17:54:26,905 INFO  crawl.Injector - Injector: update: false
2014-10-01 17:54:27,766 INFO  crawl.Injector - Injector: URLs merged: 0
2014-10-01 17:54:27,775 INFO  crawl.Injector - Injector: Total new urls injected: 0
2014-10-01 17:54:27,775 INFO  crawl.Injector - Injector: finished at 2014-10-01 17:54:27, elapsed: 00:00:02
2014-10-01 17:55:01,775 INFO  indexer.IndexingJob - Indexer: starting at 2014-10-01 17:55:01
2014-10-01 17:55:01,847 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2014-10-01 17:55:01,847 INFO  indexer.IndexingJob - Indexer: URL filtering: false
2014-10-01 17:55:01,847 INFO  indexer.IndexingJob - Indexer: URL normalizing: false
2014-10-01 17:55:02,085 INFO  indexer.IndexWriters - Adding org.apache.nutch.indexwriter.solr.SolrIndexWriter
2014-10-01 17:55:02,086 INFO  indexer.IndexingJob - Active IndexWriters :
SOLRIndexWriter
	solr.server.url : URL of the SOLR instance (mandatory)
	solr.commit.size : buffer size when sending to SOLR (default 1000)
	solr.mapping.file : name of the mapping file for fields (default solrindex-mapping.xml)
	solr.auth : use authentication (default false)
	solr.auth.username : use authentication (default false)
	solr.auth : username for authentication
	solr.auth.password : password for authentication


2014-10-01 17:55:02,094 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2014-10-01 17:55:02,094 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2014-10-01 17:55:02,094 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/*
2014-10-01 17:55:02,307 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-10-01 17:55:02,371 ERROR security.UserGroupInformation - PriviledgedActionException as:root cause:org.apache.hadoop.mapred.InvalidInputException: Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/crawl_fetch matches 0 files
Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/crawl_parse matches 0 files
Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/parse_data matches 0 files
Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/parse_text matches 0 files
Input path does not exist: file:/var/www/html/SELK/apache-nutch-1.9/crawl/crawldb/current
Input path does not exist: file:/var/www/html/SELK/apache-nutch-1.9/crawl/linkdb/current
2014-10-01 17:55:02,373 ERROR indexer.IndexingJob - Indexer: org.apache.hadoop.mapred.InvalidInputException: Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/crawl_fetch matches 0 files
Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/crawl_parse matches 0 files
Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/parse_data matches 0 files
Input Pattern file:/var/www/html/SELK/apache-nutch-1.9/crawl/segments/*/parse_text matches 0 files
Input path does not exist: file:/var/www/html/SELK/apache-nutch-1.9/crawl/crawldb/current
Input path does not exist: file:/var/www/html/SELK/apache-nutch-1.9/crawl/linkdb/current
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:197)
	at org.apache.hadoop.mapred.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:40)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:208)
	at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:1081)
	at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1073)
	at org.apache.hadoop.mapred.JobClient.access$700(JobClient.java:179)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:983)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:936)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:936)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:910)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1353)
	at org.apache.nutch.indexer.IndexingJob.index(IndexingJob.java:114)
	at org.apache.nutch.indexer.IndexingJob.run(IndexingJob.java:176)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.nutch.indexer.IndexingJob.main(IndexingJob.java:186)

2014-10-01 17:57:48,424 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-10-01 17:57:48,425 INFO  crawl.Generator - Generator: starting at 2014-10-01 17:57:48
2014-10-01 17:57:48,426 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2014-10-01 17:57:48,426 INFO  crawl.Generator - Generator: filtering: true
2014-10-01 17:57:48,426 INFO  crawl.Generator - Generator: normalizing: true
2014-10-01 17:57:48,431 INFO  crawl.Generator - Generator: jobtracker is 'local', generating exactly one partition.
2014-10-01 17:57:48,524 ERROR security.UserGroupInformation - PriviledgedActionException as:root cause:org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/var/www/html/SELK/apache-nutch-1.9/-topN/current
2014-10-01 17:57:48,526 ERROR crawl.Generator - Generator: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/var/www/html/SELK/apache-nutch-1.9/-topN/current
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:197)
	at org.apache.hadoop.mapred.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:40)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:208)
	at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:1081)
	at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:1073)
	at org.apache.hadoop.mapred.JobClient.access$700(JobClient.java:179)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:983)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:936)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:936)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:910)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1353)
	at org.apache.nutch.crawl.Generator.generate(Generator.java:548)
	at org.apache.nutch.crawl.Generator.run(Generator.java:716)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.nutch.crawl.Generator.main(Generator.java:672)

2014-10-01 18:00:26,684 INFO  crawl.Injector - Injector: starting at 2014-10-01 18:00:26
2014-10-01 18:00:26,685 INFO  crawl.Injector - Injector: crawlDb: -solr/crawldb
2014-10-01 18:00:26,685 INFO  crawl.Injector - Injector: urlDir: urls
2014-10-01 18:00:26,686 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2014-10-01 18:00:26,929 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-10-01 18:00:26,979 WARN  snappy.LoadSnappy - Snappy native library not loaded
2014-10-01 18:00:27,493 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2014-10-01 18:00:28,217 INFO  crawl.Injector - Injector: Total number of urls rejected by filters: 1
2014-10-01 18:00:28,217 INFO  crawl.Injector - Injector: Total number of urls after normalization: 0
2014-10-01 18:00:28,217 INFO  crawl.Injector - Injector: Merging injected urls into crawl db.
2014-10-01 18:00:28,422 INFO  crawl.Injector - Injector: overwrite: false
2014-10-01 18:00:28,422 INFO  crawl.Injector - Injector: update: false
2014-10-01 18:00:29,292 INFO  crawl.Injector - Injector: URLs merged: 0
2014-10-01 18:00:29,296 INFO  crawl.Injector - Injector: Total new urls injected: 0
2014-10-01 18:00:29,296 INFO  crawl.Injector - Injector: finished at 2014-10-01 18:00:29, elapsed: 00:00:02
